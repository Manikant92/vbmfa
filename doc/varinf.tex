\documentclass[a4paper]{article}
\usepackage[
    bookmarks,
    bookmarksopen=true,
    backref,
    plainpages=false,
    pdfpagelabels,
    hypertexnames=false,
    linktocpage,
    colorlinks=true,
    linkcolor=blue,
    anchorcolor=blue,
    citecolor=blue,
    filecolor=blue,
    menucolor=blue,
    urlcolor=cyan, 
]{hyperref}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage[parfill]{parskip}


\author{Angermueller Christof}
\date{\today}
\title{Variational Inference for Bayesian Mixture of Factor Analysers}

\begin{document}
\maketitle

\newcommand{\bs}{\boldsymbol}
\newcommand{\Xp}{\bs{\pi}}
\newcommand{\Xbl}{\bar{\Lambda^s}}
\newcommand{\Xn}{\bs{\nu}^s}
\newcommand{\Xe}{\Psi}
\newcommand{\Xa}{\alpha}
\newcommand{\Xc}{\Xl{\Xl}^T}

\newcommand{\Xl}{\Lambda^s}
\newcommand{\Xlmp}{\bar{\bs{\Lambda}}^s_p}
\newcommand{\Xlvp}{\Sigma^{p,s}}
\newcommand{\Xlvpi}{\Xlvp{}^{-1}}
\newcommand{\Xlvpll}{\Xlvp_{\Lambda\Lambda}}
\newcommand{\Xlvplu}{\Xlvp_{\Lambda\mu}}
\newcommand{\Xlvpul}{\Xlvp_{\mu\Lambda}}
\newcommand{\Xlvpuu}{\Xlvp_{\mu\mu}}
\newcommand{\Xlvplli}{\Xlvpll{}^{-1}}
\newcommand{\Xlvplui}{\Xlvplu{}^{-1}}
\newcommand{\Xlvpuli}{\Xlvpul{}^{-1}}
\newcommand{\Xlvpuui}{\Xlvpuu{}^{-1}}
\newcommand{\Xlt}{\tilde{\Lambda}^s}
\newcommand{\Xltb}{\tilde{{\bs{\Lambda}}}^s}
\newcommand{\Xltp}{\tilde{\bs{\Lambda}}^s_p}
\newcommand{\Xltpq}{\tilde{\Lambda}^s_{pq}}
\newcommand{\Xltm}{\bar{\tilde{\Lambda}}^s}
\newcommand{\Xltmp}{\bar{\tilde{\bs{\Lambda}}}^s_p}
\newcommand{\Xltmpq}{\bar{\tilde{\Lambda}}^s_{pq}}
\newcommand{\Xltvp}{\tilde{\Gamma}^{p,s}}
\newcommand{\Xltvpi}{\Xltvp{}^{-1}}

\newcommand{\Xu}{\bs{\mu}^s}
\newcommand{\Xup}{\mu^s_p}
\newcommand{\Xum}{\bar{\bs{\mu}}^s}
\newcommand{\Xump}{\bar{\mu}^s_p}

\newcommand{\Xx}{\bs{x}^n}
\newcommand{\Xxm}{\overline{\bs{x}}^{n,s}}
\newcommand{\Xxv}{\Sigma^s}
\newcommand{\Xxt}{\tilde{\bs{x}}^n}
\newcommand{\Xxtq}{\tilde{x}^n_q}
\newcommand{\Xxtm}{\bar{\tilde{\bs{x}}}^n}
\newcommand{\Xxtmq}{\bar{\tilde{x}}^n_q}
\newcommand{\Xxtv}{\tilde{\Sigma}^s}

% Hyperparameters
\newcommand{\Xha}{a^*}
\newcommand{\Xhb}{b^*}
\newcommand{\Xhal}{\alpha^*}
\newcommand{\Xhm}{\bs{m}^*}
\newcommand{\Xhmp}{m^*_p}
\newcommand{\Xhn}{\bs{\nu}^*}
\newcommand{\Xhnp}{\nu^*_p}

\newcommand{\Xsp}{\Sigma^{p,s}}
\newcommand{\Xxs}{\Sigma^s}
\newcommand{\Xlm}{\overline{\Lambda}^s}
\newcommand{\Xls}{\Sigma^{p,s}}
\newcommand{\Xpsii}{\Psi^{-1}}
\newcommand{\Xy}{\bs{y}^n}
\newcommand{\Xs}{s^n}
\newcommand{\Xcov}{\operatorname{cov}}
\newcommand{\Xvar}{\operatorname{var}}
\newcommand{\Xtr}{\operatorname{tr}}
\newcommand{\Xdiag}{\operatorname{diag}}
\newcommand{\Xvec}{\operatorname{vec}}

\section{Variational approximation}
The goal is to approximate the following posterior distribution:
\begin{align}
  P(\bs{\pi},\bs{\nu},\Lambda,\bs{\mu},\bs{x},\bs{s}|\bs{y})=Q(\bs{\pi},\bs{\nu},\Lambda,\bs{\mu},\bs{x},\bs{s})
\end{align}
The following approximation is assumed:
\begin{align}
  Q(\bs{\pi},\bs{\nu},\Lambda,\bs{\mu},\bs{x},\bs{s})=Q(\bs{\pi},\bs{\nu})Q(\Lambda,\bs{\mu})Q(\bs{x},\bs{s})
\end{align}
It further factorizes into:
\begin{align}
  Q(\bs{\pi},\bs{\nu})Q(\Lambda,\bs{\mu})Q(\bs{x},\bs{s})=Q(\bs{\pi})\prod_s\prod_q Q(\nu_q^s)\prod_s\prod_p Q(\tilde{\Lambda}^s_p) \prod_n Q(\Xx|\Xs)Q(\Xs)
\end{align}
Here, $\tilde{\Lambda}^s$ is the concatenation of $\Lambda^s$ and $\bs{\mu}^s$:
\begin{align}
  \tilde{\Lambda}^s:=[\Lambda^s \: \bs{\mu}^s].
\end{align}
The factors are distributed as follows:
\begin{align}
  Q(\Xp)=\mathcal{D}(\Xp|\alpha\bs{m})
\end{align}
\begin{align}
 Q(\nu^s_q)=\mathcal{G}(\nu^s_q|a, b_q^s)
\end{align}
\begin{align}
  Q(\Xlt_p)=\mathcal{N}(\Xlt_p|\Xltmp,\Xltvp)
\end{align}
\begin{align}
  Q(\Xx|\Xs)=\mathcal{N}(\Xx|\Xxm,\Xxv)
\end{align}
\begin{align}
  Q(\Xs)\text{ is }N\times S
\end{align}

\subsection{$Q(\Xp)$}
\begin{align}
  Q(\Xp)=\mathcal{D}(\Xp|\alpha\bs{m})
\end{align}
\begin{align}
  \alpha m_s=\alpha^*m^*_s+\sum_n Q(s^n)
\end{align}

\subsection{$Q(\nu_q^s)$}
\begin{align}
 Q(\nu^s_q)=\mathcal{G}(\nu^s_q|a, b_q^s)
\end{align}
\begin{align}
a&=a^*+\frac{P}{2} \\
b_q^s&=b^*+\frac{1}{2}\sum_p<\Xl_{pq}{}^2> \\
&=b+\frac{1}{2}\sum_p\left(\Xltmpq{}^2 + \Xltvp_{qq}\right)
\end{align}
Here, we solved $<\Xlt_{pq}{}^2>$ by eq.~\ref{eq:x2}.

\subsection{$Q(\Xlt_p)$}
\begin{align}
  Q(\Xltp)=\mathcal{N}(\Xltp|\Xltmp,\Xltvp)
\end{align}
The extended loading matrix $\Xlt$ is $P\times (Q+1)$ and factorizes over rows:
\begin{align}
  \Xlt=\left[
    \begin{array}{ccc|c}
      \Xl_{11} & \cdots & \Xl_{1Q} & \mu^s_1 \\
      \vdots & \vdots & \vdots & \vdots \\
      \Xl_{p1} & \cdots & \Xl_{pQ} & \mu^s_p \\
      \vdots & \vdots & \vdots & \vdots \\
      \Xl_{P1} & \cdots & \Xl_{PQ} & \mu^s_P
    \end{array}
  \right]
\end{align}
The row mean is $(Q+1)\times 1$:
\begin{align}
  \Xltmp=\begin{bmatrix}
    \Xlmp \\
    \Xump
  \end{bmatrix}
\end{align}
\begin{align}
  \Xlmp
  &=\Xltvp_{\Lambda\Lambda}\left(\Xpsii_{pp}\sum_n Q(\Xs)y^n_p<\Xx>\right) \\
  &=\Xltvp_{\Lambda\Lambda}\left(\Xpsii_{pp}\sum_n Q(\Xs)y^n_p\Xxm\right)
\end{align}
\begin{align}
  \Xump
  &=\Xltvp_{\mu\mu}\left(\Xpsii_{pp}\sum_n Q(\Xs)y^n_p+\nu^*_p\mu^*_p\right)
\end{align}
The row covariance matrix is $P\times(Q+1)$ and decomposes into $4$ blocks:
\begin{align}
  \Xltvpi=\begin{bmatrix}
    \Xlvplli & \Xlvplui \\
    \Xlvpuli & \Xlvpuui
  \end{bmatrix}
\end{align}
$\Xlvpll$ is $Q\times Q$:
\begin{align}
  \Xlvplli
  &=\Xdiag[<\Xn>]+\Xpsii\sum_n Q(\Xs)<\Xx{\Xx}^T> \\
  &=\Xdiag[\frac{a}{b^s_1},...,\frac{a}{b^s_Q}]+\Xpsii\sum_n Q(\Xs)\left(\Xxm{\Xxm}^T+\Xxv\right) \label{eq:ulvppli}
\end{align}
Eq.~\ref{eq:ulvppli} follows from eq.~\ref{eq:xx}. \\
$\Xlvplui$ is $Q\times 1$:
\begin{align}
  \Xlvplui
  &=\Xpsii_{pp}\sum_n Q(\Xs)<\Xx> \\
  &=\Xpsii_{pp}\sum_n Q(\Xs)\Xxm
\end{align}
$\Xlvpuu$ is $1\times 1$:
\begin{align}
  \Xlvpuui&=
  \nu^*_p+\Xpsii_{pp}\sum_n Q(\Xs)
\end{align}

\subsection{$Q(\Xx|\Xs)$}
\begin{align}
  Q(\Xx|\Xs)=\mathcal{N}(\Xx|\Xxm,\Xxv)
\end{align}
\begin{align}
  \Xxm
  &=\Xxv<{\Xl}^T\Xpsii(\Xy-\Xu)> \\
  &=\Xxv\left[{\Xlm}^T\Xpsii\left(\Xy-\Xum\right)-\bs{v}\right] \label{eq:uxxm}
\end{align}
Eq.~\ref{eq:uxxm} follows from eq.~\ref{eq:XAy} and $\bs{v}$ is defined as
\begin{align}
  v_q
  &=\Xtr[\Xpsii\Xcov[\Xl_{:q},\Xu]] \\
  &=\sum_p \Xpsii_{pp} {\Xlvplu}_q. \label{eq:uxxmv}
\end{align}
Eq.~\ref{eq:uxxmv} follows from $\Xcov[\Xl_{pq},\mu^s_{p^\prime}]=0$ if $p\neq p^\prime$ and $\Xcov[\Xl_{pq},\mu^s_{p}]={\Xlvplu}_q$.
\begin{align}
  {\Xxs}^{-1}=<{\Xl}^T \Xpsii \Xl>+I
\end{align}
$<{\Xl}^T \Xpsii \Xl>$ is solved by eq. $\ref{eq:XAY}$ and $\Xcov[\Xl_{pi},\Xl_{p^\prime j}]=0$ for $p\ne p^\prime$:
\begin{align}
  <{\Xl}^T \Xpsii \Xl>_{ij}&=<{\Xl_{:i}}^T \Xpsii \Xl_{:j}> \\
  &=<\Xl_{:i}>^T\Xpsii <\Xl_{:j}>+\sum_p\sum_{p^\prime} \Xpsii_{pp^\prime}\Xcov[\Xl_{pi},\Xl_{p^\prime j}] \\
  &=<\Xl_{:i}>^T\Xpsii <\Xl_{:j}>+\sum_p \Xpsii_{pp}\Xcov[\Xl_{pi},\Xl_{pj}] \\
  &={\Xlm_{:i}}^T\Xpsii \Xlm_{:j}+\sum_p \Xpsii_{pp}{\Xlvpll}_{ij}
\end{align}

\subsection{$Q(\Xs)$}
\begin{align}
  \ln Q(\Xs)
  &=\psi(\alpha m_s)+\frac{1}{2}\ln |\Xxs|+<\ln P(\Xy|\Xx,\Xs,\Xl,\Psi)> \label{eq:usqe} \\
  &=\psi(\alpha m_s)+\frac{1}{2}\ln |\Xxs| \nonumber \\
  &\quad-\frac{1}{2}\Xtr[\Xpsii(\Xy-\Xltm\Xxtm)(\Xy-\Xltm\Xxtm)^T] \nonumber \\
  &\quad-\frac{1}{2}\sum_p\Xpsii_{pp}\left(\sum_q\Xltmpq{}^2\Xxtv_{qq}+\Xxtmq{}^2\Xltvp_{qq}+\Xltvp_{qq}\Xxtv_{qq}\right)
\end{align}
$\Xxt$ is defined as:
\begin{align}
  \Xxt=
  \begin{bmatrix}
    \Xx \\
    1
  \end{bmatrix}
\end{align}
The expectation in eq.~\ref{eq:usqe} is:
\begin{align}
  <\ln P(\Xy|\Xx,\Xs,\Xl,\Psi)>=-\frac{1}{2}\Xtr[\Xpsii<(\Xy-\Xlt\Xxt)(\Xy-\Xlt\Xxt)^T>]+\text{const} \label{eq:usle}
\end{align}
\begin{align}
  <(\Xy-\Xlt\Xxt)(\Xy-\Xlt\Xxt)^T>
  &=(\Xy-\Xltm\Xxtm)(\Xy-\Xltm\Xxtm)^T+\Xcov[\Xy-\Xlt\Xxt]] \label{eq:use2} \\
  &=(\Xy-\Xltm\Xxtm)(\Xy-\Xltm\Xxtm)^T+V \label{eq:use}
\end{align}
Eq.~\ref{eq:use2} follows from eq.~\ref{eq:xx}. \\
$V$ is diagonal, since rows are indepenent:
\begin{align}
  V=
  \begin{bmatrix}
    \Xvar[\Xltb_1{}^T\Xxt] & \cdots & 0 \\
    \cdots & \Xvar[\Xltb_p{}^T\Xxt] & \cdots \\
    0   & \cdots & \Xvar[\Xltb_P{}^T\Xxt]
  \end{bmatrix}
\end{align}
\begin{align}
  \Xvar[\Xltp{}^T\Xxt]
  &=\sum_q\Xvar[\Xltpq\Xxtq] \\
  &=\sum_q<\Xltpq{}^2><\Xxtq{}^2>-<\Xltpq>^2<\Xxtq>^2 \label{eq:usv1} \\
  &=\sum_q(<\Xltpq>^2+\Xvar[\Xltpq])(<\Xxtq>^2+\Xvar[\Xxtq])-<\Xltpq>^2<\Xxtq>^2 \label{eq:usv2} \\
  &=\sum_q<\Xltpq>^2\Xvar[\Xxtq]+<\Xxtq>^2\Xvar[\Xltpq]+\Xvar[\Xltpq]\Xvar[\Xxtq] \\
  &=\sum_q\Xltmpq{}^2\Xxtv_{qq}+\Xxtmq{}^2\Xltvp_{qq}+\Xltvp_{qq}\Xxtv_{qq}
\end{align}
Eq.~\ref{eq:usv1} follows from eq.~\ref{eq:vxy}, eq.~\ref{eq:usv2} from eq.~\ref{eq:x2}. \\
Eq.~\ref{eq:use} can now be resubsituted into eq.~\ref{eq:usle}:
\begin{align}
  <\ln P(\Xy|\Xx,\Xs,\Xl,\Psi)>
  &=-\frac{1}{2}\Xtr[\Xpsii <(\Xy-\Xlt\Xxt)(\Xy-\Xlt\Xxt)^T>] \\
  &=-\frac{1}{2}\Xtr[\Xpsii \left((\Xy-\Xltm\Xxtm)(\Xy-\Xltm\Xxtm)^T+V\right)] \\
  &=-\frac{1}{2}\Xtr[\Xpsii(\Xy-\Xltm\Xxtm)(\Xy-\Xltm\Xxtm)^T + \Xpsii V] \\
  &=-\frac{1}{2}\Xtr[\Xpsii(\Xy-\Xltm\Xxtm)(\Xy-\Xltm\Xxtm)^T] \nonumber \\
  &\quad-\frac{1}{2}\sum_p\Xpsii_{pp}\left(\sum_q\Xltmpq{}^2\Xxtv_{qq}+\Xxtmq{}^2\Xltvp_{qq}+\Xltvp_{qq}\Xxtv_{qq}\right) \label{eq:usef}
\end{align}
Eq.~\ref{eq:usef} can now be resubsituted into eq.~\ref{eq:usqe}:
\begin{align}
  \ln Q(\Xs)
  &=\psi(\alpha m_s)+\frac{1}{2}\ln |\Xxs|+<\ln P(\Xy|\Xx,\Xs,\Xl,\Psi)> \\
  &=\psi(\alpha m_s)+\frac{1}{2}\ln |\Xxs| \nonumber \\
  &\quad-\frac{1}{2}\Xtr[\Xpsii(\Xy-\Xltm\Xxtm)(\Xy-\Xltm\Xxtm)^T] \nonumber \\
  &\quad-\frac{1}{2}\sum_p\Xpsii_{pp}\left(\sum_q\Xltmpq{}^2\Xxtv_{qq}+\Xxtmq{}^2\Xltvp_{qq}+\Xltvp_{qq}\Xxtv_{qq}\right)
\end{align}

\section{Equations}
\newcommand{\Xvx}{\bs{x}}
\newcommand{\Xvy}{\bs{y}}

\begin{align}
  \label{eq:x2}
  <\bs{x}^2>=<\bs{x}>^2+\Xvar[\bs{x}]
\end{align}
\begin{align}
  \label{eq:xAx}
  <\bs{x}^T A \bs{x}>=<\bs{x}>^T A <\bs{x}> + \Xtr[A \Xvar[\bs{x}]]
\end{align}
\begin{align}
  \label{eq:xAy}
  <\bs{x}^T A \bs{y}>
  &=<\bs{x}>^T A <\bs{y}> + \Xtr[A \Xcov[\bs{y},\bs{x}]] \\
  &=<\bs{x}>^T A <\bs{y}> + \Xvec[A]^T\Xvec[\Xcov[\bs{x},\bs{y}]]
\end{align}
\begin{align}
  \label{eq:XAY}
  <X A Y>&=<X>A<Y>+V \\
  V_{ij}&=\Xtr[A\Xcov[Y_{:j},X_i]]=\Xvec[A]^T\Xvec[\Xcov[X_i,Y_{:j}]] \nonumber
\end{align}
\begin{align}
  \label{eq:XAy}
  <X A \bs{y}>&=<X>A<\bs{y}>+\bs{v} \\
  \bs{v}_{i}&=\Xtr[A\Xcov[\bs{y},A_i]]=\Xvec[A]^T\Xvec[\Xcov[X_i,\bs{y}]] \nonumber
\end{align}
\begin{align}
  \label{eq:xx}
  <\bs{x}\bs{x}^T>=<\bs{x}><\bs{x}>^T+ \Xcov[\bs{x}]
\end{align}
If $M$ and $\Xvx$ are independent:
\begin{align}
  \label{eq:Mx}
  <M \Xvx>=<M><\Xvx>
\end{align}
If $\Xvx$ and $\Xvy$ are independent:
\begin{align}
  \Xvar[\Xvx^T\Xvy]
  &=\sum_i \Xvar[\Xvx_i \Xvy_i] \nonumber\\
  &=\sum_i <\Xvx_i^2><\Xvy_i^2> - <\Xvx_i>^2<\Xvy_i>^2 \label{eq:vxy}
\end{align}


\end{document}
